{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca60b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Input, Dense, Lambda, concatenate, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c54110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.11673</td>\n",
       "      <td>-0.11472</td>\n",
       "      <td>-0.11267</td>\n",
       "      <td>-0.10309</td>\n",
       "      <td>-0.087613</td>\n",
       "      <td>-0.090371</td>\n",
       "      <td>-0.093053</td>\n",
       "      <td>-0.087851</td>\n",
       "      <td>-0.080475</td>\n",
       "      <td>-0.073482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080908</td>\n",
       "      <td>0.077866</td>\n",
       "      <td>0.074388</td>\n",
       "      <td>0.093335</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.175100e-17</td>\n",
       "      <td>-7.536600e-17</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-8.080700e-19</td>\n",
       "      <td>1.259300e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.11673</td>\n",
       "      <td>-0.11472</td>\n",
       "      <td>-0.11267</td>\n",
       "      <td>-0.10309</td>\n",
       "      <td>-0.087613</td>\n",
       "      <td>-0.090371</td>\n",
       "      <td>-0.093053</td>\n",
       "      <td>-0.087851</td>\n",
       "      <td>-0.080475</td>\n",
       "      <td>-0.073482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080809</td>\n",
       "      <td>0.077486</td>\n",
       "      <td>0.074208</td>\n",
       "      <td>0.092037</td>\n",
       "      <td>0.98019</td>\n",
       "      <td>2.812100e-02</td>\n",
       "      <td>3.839000e-02</td>\n",
       "      <td>0.95191</td>\n",
       "      <td>3.804000e-05</td>\n",
       "      <td>5.106000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.11673</td>\n",
       "      <td>-0.11472</td>\n",
       "      <td>-0.11267</td>\n",
       "      <td>-0.10309</td>\n",
       "      <td>-0.087613</td>\n",
       "      <td>-0.090371</td>\n",
       "      <td>-0.093053</td>\n",
       "      <td>-0.087851</td>\n",
       "      <td>-0.080475</td>\n",
       "      <td>-0.073482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078726</td>\n",
       "      <td>0.075340</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.089668</td>\n",
       "      <td>0.87481</td>\n",
       "      <td>-2.911400e-02</td>\n",
       "      <td>-1.860100e-01</td>\n",
       "      <td>0.82133</td>\n",
       "      <td>2.547400e-03</td>\n",
       "      <td>-4.391200e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.11673</td>\n",
       "      <td>-0.11472</td>\n",
       "      <td>-0.11267</td>\n",
       "      <td>-0.10309</td>\n",
       "      <td>-0.087613</td>\n",
       "      <td>-0.090371</td>\n",
       "      <td>-0.093053</td>\n",
       "      <td>-0.087851</td>\n",
       "      <td>-0.080475</td>\n",
       "      <td>-0.073482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095130</td>\n",
       "      <td>0.098271</td>\n",
       "      <td>0.101310</td>\n",
       "      <td>0.104860</td>\n",
       "      <td>1.07530</td>\n",
       "      <td>2.159500e-01</td>\n",
       "      <td>-8.996700e-01</td>\n",
       "      <td>0.23954</td>\n",
       "      <td>1.420900e-04</td>\n",
       "      <td>-2.732800e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.11673</td>\n",
       "      <td>-0.11472</td>\n",
       "      <td>-0.11267</td>\n",
       "      <td>-0.10309</td>\n",
       "      <td>-0.087613</td>\n",
       "      <td>-0.090371</td>\n",
       "      <td>-0.093053</td>\n",
       "      <td>-0.087851</td>\n",
       "      <td>-0.080475</td>\n",
       "      <td>-0.073482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115330</td>\n",
       "      <td>0.119470</td>\n",
       "      <td>0.125280</td>\n",
       "      <td>0.131740</td>\n",
       "      <td>1.90660</td>\n",
       "      <td>-3.081800e-01</td>\n",
       "      <td>1.102200e-01</td>\n",
       "      <td>1.61070</td>\n",
       "      <td>-1.758700e-02</td>\n",
       "      <td>1.708500e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 406 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2        3         4         5         6         7    \\\n",
       "0 -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053 -0.087851   \n",
       "1 -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053 -0.087851   \n",
       "2 -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053 -0.087851   \n",
       "3 -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053 -0.087851   \n",
       "4 -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053 -0.087851   \n",
       "\n",
       "        8         9    ...       396       397       398       399      400  \\\n",
       "0 -0.080475 -0.073482  ...  0.080908  0.077866  0.074388  0.093335  1.00000   \n",
       "1 -0.080475 -0.073482  ...  0.080809  0.077486  0.074208  0.092037  0.98019   \n",
       "2 -0.080475 -0.073482  ...  0.078726  0.075340  0.071999  0.089668  0.87481   \n",
       "3 -0.080475 -0.073482  ...  0.095130  0.098271  0.101310  0.104860  1.07530   \n",
       "4 -0.080475 -0.073482  ...  0.115330  0.119470  0.125280  0.131740  1.90660   \n",
       "\n",
       "            401           402      403           404           405  \n",
       "0  9.175100e-17 -7.536600e-17  1.00000 -8.080700e-19  1.259300e-18  \n",
       "1  2.812100e-02  3.839000e-02  0.95191  3.804000e-05  5.106000e-04  \n",
       "2 -2.911400e-02 -1.860100e-01  0.82133  2.547400e-03 -4.391200e-03  \n",
       "3  2.159500e-01 -8.996700e-01  0.23954  1.420900e-04 -2.732800e-03  \n",
       "4 -3.081800e-01  1.102200e-01  1.61070 -1.758700e-02  1.708500e-02  \n",
       "\n",
       "[5 rows x 406 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('MPEG7_DBLabled.csv',header = None)\n",
    "dataframe.head()\n",
    "#dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c1441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0        1        2        3         4         5         6    \\\n",
      "0     -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053   \n",
      "1     -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053   \n",
      "2     -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053   \n",
      "3     -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053   \n",
      "4     -0.11673 -0.11472 -0.11267 -0.10309 -0.087613 -0.090371 -0.093053   \n",
      "...        ...      ...      ...      ...       ...       ...       ...   \n",
      "27995  0.29401  0.28846  0.27917  0.26606  0.195010  0.183130  0.166160   \n",
      "27996  0.29401  0.28846  0.27917  0.26606  0.195010  0.183130  0.166160   \n",
      "27997  0.29401  0.28846  0.27917  0.26606  0.195010  0.183130  0.166160   \n",
      "27998  0.29401  0.28846  0.27917  0.26606  0.195010  0.183130  0.166160   \n",
      "27999  0.29401  0.28846  0.27917  0.26606  0.195010  0.183130  0.166160   \n",
      "\n",
      "            7         8         9    ...       396       397       398  \\\n",
      "0     -0.087851 -0.080475 -0.073482  ...  0.080908  0.077866  0.074388   \n",
      "1     -0.087851 -0.080475 -0.073482  ...  0.080809  0.077486  0.074208   \n",
      "2     -0.087851 -0.080475 -0.073482  ...  0.078726  0.075340  0.071999   \n",
      "3     -0.087851 -0.080475 -0.073482  ...  0.095130  0.098271  0.101310   \n",
      "4     -0.087851 -0.080475 -0.073482  ...  0.115330  0.119470  0.125280   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "27995  0.153750  0.139740  0.128140  ... -0.023006 -0.015039 -0.002983   \n",
      "27996  0.153750  0.139740  0.128140  ... -0.051519 -0.042107 -0.034373   \n",
      "27997  0.153750  0.139740  0.128140  ... -0.023980 -0.009712  0.002153   \n",
      "27998  0.153750  0.139740  0.128140  ... -0.076829 -0.068990 -0.062297   \n",
      "27999  0.153750  0.139740  0.128140  ... -0.012924 -0.005594  0.014840   \n",
      "\n",
      "            399      400           401           402      403           404  \\\n",
      "0      0.093335  1.00000  9.175100e-17 -7.536600e-17  1.00000 -8.080700e-19   \n",
      "1      0.092037  0.98019  2.812100e-02  3.839000e-02  0.95191  3.804000e-05   \n",
      "2      0.089668  0.87481 -2.911400e-02 -1.860100e-01  0.82133  2.547400e-03   \n",
      "3      0.104860  1.07530  2.159500e-01 -8.996700e-01  0.23954  1.420900e-04   \n",
      "4      0.131740  1.90660 -3.081800e-01  1.102200e-01  1.61070 -1.758700e-02   \n",
      "...         ...      ...           ...           ...      ...           ...   \n",
      "27995  0.020509 -0.88273 -1.653300e-01  3.924600e-02  0.83799 -2.398400e-02   \n",
      "27996 -0.011313 -1.51190 -2.626500e-01  2.389700e-02  1.51440 -2.600400e-02   \n",
      "27997  0.010746  1.10490 -7.640400e-01  6.124500e-02  0.68991  3.703400e-02   \n",
      "27998 -0.053576  0.71266  2.045500e-01 -1.903600e-01  0.35335  1.054200e-02   \n",
      "27999  0.024072  1.00000 -3.087900e-17  1.004200e-17  1.00000 -8.521200e-19   \n",
      "\n",
      "                405  \n",
      "0      1.259300e-18  \n",
      "1      5.106000e-04  \n",
      "2     -4.391200e-03  \n",
      "3     -2.732800e-03  \n",
      "4      1.708500e-02  \n",
      "...             ...  \n",
      "27995 -2.101800e-03  \n",
      "27996 -6.553100e-03  \n",
      "27997 -5.589700e-03  \n",
      "27998 -4.459200e-03  \n",
      "27999  2.176300e-18  \n",
      "\n",
      "[28000 rows x 406 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6983f76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 406)\n",
      "[[-1.1673e-01 -1.1472e-01 -1.1267e-01 ...  1.0000e+00 -8.0807e-19\n",
      "   1.2593e-18]\n",
      " [-1.1673e-01 -1.1472e-01 -1.1267e-01 ...  9.5191e-01  3.8040e-05\n",
      "   5.1060e-04]\n",
      " [-1.1673e-01 -1.1472e-01 -1.1267e-01 ...  8.2133e-01  2.5474e-03\n",
      "  -4.3912e-03]\n",
      " ...\n",
      " [ 2.9401e-01  2.8846e-01  2.7917e-01 ...  6.8991e-01  3.7034e-02\n",
      "  -5.5897e-03]\n",
      " [ 2.9401e-01  2.8846e-01  2.7917e-01 ...  3.5335e-01  1.0542e-02\n",
      "  -4.4592e-03]\n",
      " [ 2.9401e-01  2.8846e-01  2.7917e-01 ...  1.0000e+00 -8.5212e-19\n",
      "   2.1763e-18]]\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(dataframe).to_numpy()\n",
    "print(dataframe.shape)\n",
    "print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbdcd01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 406)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(100)\n",
    "random.shuffle(dataframe)\n",
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc6c1595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 200)\n",
      "(28000, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Current_contours=dataframe[:,0:200]\n",
    "#print(contours[1,0:200])\n",
    "print(Current_contours.shape)\n",
    "post_Contours=dataframe[:,200:400]\n",
    "print(post_Contours.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "342c92f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0000e+00  9.1751e-17 -7.5366e-17  1.0000e+00 -8.0807e-19  1.2593e-18]\n",
      "(28000, 6)\n"
     ]
    }
   ],
   "source": [
    "Transformation_matrix=dataframe[:,400:406]\n",
    "print(Transformation_matrix[0,:])\n",
    "print(Transformation_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d21b9b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#print classes and subclasses\\n\",\n",
    "Subclass_class=dataframe[:,406:408]\n",
    "print(Subclass_class.astype(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c338de05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 2, 100, 1)\n",
      "(28000, 2, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "Reshape_CurreCon = Current_contours.reshape((Current_contours.shape[0], 2,100,1))\n",
    "print(Reshape_CurreCon.shape)\n",
    "Reshape_PostCon = post_Contours.reshape((post_Contours.shape[0], 2,100,1))\n",
    "print(Reshape_PostCon.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "814336c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = int(Reshape_CurreCon.shape[0] * 0.75)\n",
    "print(train_size)\n",
    "test_size = int(Reshape_CurreCon.shape[0] * 0.25)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a55238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_left_train = Reshape_CurreCon[:train_size]\n",
    "data_right_train = Reshape_PostCon[:train_size]\n",
    "affine_matrices_train = Transformation_matrix[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782628fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left_test = Reshape_CurreCon[-test_size:]\n",
    "data_right_test = Reshape_PostCon[-test_size:]\n",
    "affine_matrices_test = Transformation_matrix[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0d7eb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building siamese network...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow.keras.backend as K\n",
    "shape= (2,100,1) \n",
    "#Les entrÃ©es des deux modele siamese\n",
    "print(\"[INFO] building siamese network...\")\n",
    "input_1 =tf.keras.layers.Input(shape) \n",
    "input_2 =tf.keras.layers.Input(shape)\n",
    "## DÃ©finir le modÃ¨le siamese profond\n",
    "model =keras.Sequential()\n",
    "# Ajout de couches de convolution et de pooling\n",
    "model.add(keras.layers.Conv2D(16, kernel_size=(1,1), activation='relu',  padding='same', input_shape=shape, name=\"Conv2D_1\"))\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(1,1), activation='relu',  padding='same', name=\"Conv2D_2\"))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(1,1), activation='relu',  padding='same', name=\"Conv2D_3\"))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(1,1), name=\"MaxPooling2D_1\"))\n",
    "\n",
    "\n",
    "# Conversion en vecteur et ajout de couches fully-connected\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "# Appliquer le modÃ¨le sur chaque entrÃ©e\n",
    "# As mentioned above, Siamese Network share weights between  tower networks (sister networks).\n",
    "#To allow this, we will use same embedding network for both tower networks.\n",
    "tower_1 = model(input_1) #siamese 1\n",
    "tower_2 = model(input_2) #siamese 2\n",
    "\n",
    " # Concatenate the encoded inputs\n",
    "    # Application de la fonction de distance L2 aux sorties de chaque branche\n",
    "#concatenated = Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "concatenated = concatenate([tower_1, tower_2])\n",
    "\n",
    "# Fully connected layers for prediction !!!!!!! fxer le nombre des noeuds\n",
    "fc = Dense(50, activation='relu')(concatenated)\n",
    "fc = Dense(50, activation='relu')(fc)\n",
    "fc = Dense(50, activation='relu')(fc)\n",
    "# Output layer for the affine transformation matrix\n",
    "output = Dense(6, activation='linear')(fc)\n",
    "    \n",
    "siamese_net =keras.Model(inputs=[input_1,input_2],outputs=output)\n",
    "\n",
    "#print(model.summary())\n",
    "#print(siamese_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8934907c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/150\n",
      "329/329 [==============================] - 21s 59ms/step - loss: 0.1136 - mse: 0.1136 - mae: 0.1707 - accuracy: 0.6233 - val_loss: 0.2002 - val_mse: 0.2002 - val_mae: 0.1448 - val_accuracy: 0.6301\n",
      "Epoch 2/150\n",
      "329/329 [==============================] - 18s 53ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.1059 - accuracy: 0.6852 - val_loss: 0.1585 - val_mse: 0.1585 - val_mae: 0.1218 - val_accuracy: 0.6896\n",
      "Epoch 3/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0413 - mse: 0.0413 - mae: 0.0933 - accuracy: 0.7222 - val_loss: 0.1135 - val_mse: 0.1135 - val_mae: 0.1224 - val_accuracy: 0.6906\n",
      "Epoch 4/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0417 - mse: 0.0417 - mae: 0.0915 - accuracy: 0.7382 - val_loss: 0.1089 - val_mse: 0.1089 - val_mae: 0.1055 - val_accuracy: 0.7263\n",
      "Epoch 5/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0278 - mse: 0.0278 - mae: 0.0772 - accuracy: 0.7670 - val_loss: 0.1253 - val_mse: 0.1253 - val_mae: 0.1027 - val_accuracy: 0.7451\n",
      "Epoch 6/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0249 - mse: 0.0249 - mae: 0.0741 - accuracy: 0.7768 - val_loss: 0.1033 - val_mse: 0.1033 - val_mae: 0.0980 - val_accuracy: 0.7594\n",
      "Epoch 7/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0256 - mse: 0.0256 - mae: 0.0741 - accuracy: 0.7805 - val_loss: 0.1011 - val_mse: 0.1011 - val_mae: 0.0966 - val_accuracy: 0.7601\n",
      "Epoch 8/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.0663 - accuracy: 0.7998 - val_loss: 0.1078 - val_mse: 0.1078 - val_mae: 0.1088 - val_accuracy: 0.7453\n",
      "Epoch 9/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0193 - mse: 0.0193 - mae: 0.0645 - accuracy: 0.8057 - val_loss: 0.0887 - val_mse: 0.0887 - val_mae: 0.0963 - val_accuracy: 0.7719\n",
      "Epoch 10/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0233 - mse: 0.0233 - mae: 0.0656 - accuracy: 0.7975 - val_loss: 0.1215 - val_mse: 0.1215 - val_mae: 0.1069 - val_accuracy: 0.7351\n",
      "Epoch 11/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0190 - mse: 0.0190 - mae: 0.0650 - accuracy: 0.8059 - val_loss: 0.0905 - val_mse: 0.0905 - val_mae: 0.0893 - val_accuracy: 0.7717\n",
      "Epoch 12/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0171 - mse: 0.0171 - mae: 0.0635 - accuracy: 0.8033 - val_loss: 0.0867 - val_mse: 0.0867 - val_mae: 0.0964 - val_accuracy: 0.7763\n",
      "Epoch 13/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0604 - accuracy: 0.8145 - val_loss: 0.1226 - val_mse: 0.1226 - val_mae: 0.1046 - val_accuracy: 0.7617\n",
      "Epoch 14/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0166 - mse: 0.0166 - mae: 0.0629 - accuracy: 0.7955 - val_loss: 0.1023 - val_mse: 0.1023 - val_mae: 0.1227 - val_accuracy: 0.7141\n",
      "Epoch 15/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0589 - accuracy: 0.8154 - val_loss: 0.1200 - val_mse: 0.1200 - val_mae: 0.0881 - val_accuracy: 0.8003\n",
      "Epoch 16/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0191 - mse: 0.0191 - mae: 0.0642 - accuracy: 0.8060 - val_loss: 0.0987 - val_mse: 0.0987 - val_mae: 0.0848 - val_accuracy: 0.7893\n",
      "Epoch 17/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0177 - mse: 0.0177 - mae: 0.0604 - accuracy: 0.8143 - val_loss: 0.1013 - val_mse: 0.1013 - val_mae: 0.0888 - val_accuracy: 0.7976\n",
      "Epoch 18/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0183 - mse: 0.0183 - mae: 0.0579 - accuracy: 0.8157 - val_loss: 0.0755 - val_mse: 0.0755 - val_mae: 0.0796 - val_accuracy: 0.8116\n",
      "Epoch 19/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0515 - accuracy: 0.8359 - val_loss: 0.0924 - val_mse: 0.0924 - val_mae: 0.0840 - val_accuracy: 0.7941\n",
      "Epoch 20/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0506 - accuracy: 0.8380 - val_loss: 0.0811 - val_mse: 0.0811 - val_mae: 0.0903 - val_accuracy: 0.7677\n",
      "Epoch 21/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.0581 - accuracy: 0.8151 - val_loss: 0.0741 - val_mse: 0.0741 - val_mae: 0.0791 - val_accuracy: 0.7770\n",
      "Epoch 22/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0493 - accuracy: 0.8338 - val_loss: 0.0935 - val_mse: 0.0935 - val_mae: 0.1095 - val_accuracy: 0.7406\n",
      "Epoch 23/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0156 - mse: 0.0156 - mae: 0.0603 - accuracy: 0.8084 - val_loss: 0.0737 - val_mse: 0.0737 - val_mae: 0.0826 - val_accuracy: 0.7893\n",
      "Epoch 24/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0505 - accuracy: 0.8299 - val_loss: 0.0698 - val_mse: 0.0698 - val_mae: 0.0758 - val_accuracy: 0.8124\n",
      "Epoch 25/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0453 - accuracy: 0.8439 - val_loss: 0.0750 - val_mse: 0.0750 - val_mae: 0.0861 - val_accuracy: 0.8053\n",
      "Epoch 26/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0539 - accuracy: 0.8218 - val_loss: 0.0721 - val_mse: 0.0721 - val_mae: 0.0749 - val_accuracy: 0.8001\n",
      "Epoch 27/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0424 - accuracy: 0.8497 - val_loss: 0.0690 - val_mse: 0.0690 - val_mae: 0.0761 - val_accuracy: 0.8010\n",
      "Epoch 28/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0437 - accuracy: 0.8467 - val_loss: 0.0816 - val_mse: 0.0816 - val_mae: 0.0765 - val_accuracy: 0.7944\n",
      "Epoch 29/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0457 - accuracy: 0.8465 - val_loss: 0.0816 - val_mse: 0.0816 - val_mae: 0.0747 - val_accuracy: 0.8061\n",
      "Epoch 30/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0477 - accuracy: 0.8399 - val_loss: 0.0689 - val_mse: 0.0689 - val_mae: 0.0734 - val_accuracy: 0.8050\n",
      "Epoch 31/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0422 - accuracy: 0.8511 - val_loss: 0.0821 - val_mse: 0.0821 - val_mae: 0.1018 - val_accuracy: 0.7690\n",
      "Epoch 32/150\n",
      "329/329 [==============================] - 18s 55ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0435 - accuracy: 0.8411 - val_loss: 0.0905 - val_mse: 0.0905 - val_mae: 0.0966 - val_accuracy: 0.7890\n",
      "Epoch 33/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0538 - accuracy: 0.8268 - val_loss: 0.1103 - val_mse: 0.1103 - val_mae: 0.0887 - val_accuracy: 0.7887\n",
      "Epoch 34/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0509 - accuracy: 0.8263 - val_loss: 0.0689 - val_mse: 0.0689 - val_mae: 0.0945 - val_accuracy: 0.7927\n",
      "Epoch 35/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0462 - accuracy: 0.8393 - val_loss: 0.0767 - val_mse: 0.0767 - val_mae: 0.0715 - val_accuracy: 0.8243\n",
      "Epoch 36/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0415 - accuracy: 0.8547 - val_loss: 0.0645 - val_mse: 0.0645 - val_mae: 0.0730 - val_accuracy: 0.8207\n",
      "Epoch 37/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0393 - accuracy: 0.8559 - val_loss: 0.0731 - val_mse: 0.0731 - val_mae: 0.0713 - val_accuracy: 0.8123\n",
      "Epoch 38/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0419 - accuracy: 0.8533 - val_loss: 0.0664 - val_mse: 0.0664 - val_mae: 0.0701 - val_accuracy: 0.8079\n",
      "Epoch 39/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0364 - accuracy: 0.8674 - val_loss: 0.0704 - val_mse: 0.0704 - val_mae: 0.0753 - val_accuracy: 0.8027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0369 - accuracy: 0.8666 - val_loss: 0.0744 - val_mse: 0.0744 - val_mae: 0.0729 - val_accuracy: 0.8286\n",
      "Epoch 41/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0371 - accuracy: 0.8635 - val_loss: 0.0738 - val_mse: 0.0738 - val_mae: 0.0882 - val_accuracy: 0.8124\n",
      "Epoch 42/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0424 - accuracy: 0.8535 - val_loss: 0.0759 - val_mse: 0.0759 - val_mae: 0.0844 - val_accuracy: 0.8169\n",
      "Epoch 43/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0379 - accuracy: 0.8626 - val_loss: 0.0658 - val_mse: 0.0658 - val_mae: 0.0679 - val_accuracy: 0.8327\n",
      "Epoch 44/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0372 - accuracy: 0.8639 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.0787 - val_accuracy: 0.8041\n",
      "Epoch 45/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0365 - accuracy: 0.8654 - val_loss: 0.0671 - val_mse: 0.0671 - val_mae: 0.0709 - val_accuracy: 0.7901\n",
      "Epoch 46/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0406 - accuracy: 0.8540 - val_loss: 0.0874 - val_mse: 0.0874 - val_mae: 0.0906 - val_accuracy: 0.7897\n",
      "Epoch 47/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0487 - accuracy: 0.8366 - val_loss: 0.0848 - val_mse: 0.0848 - val_mae: 0.0853 - val_accuracy: 0.8126\n",
      "Epoch 48/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0509 - accuracy: 0.8341 - val_loss: 0.0859 - val_mse: 0.0859 - val_mae: 0.0731 - val_accuracy: 0.8189\n",
      "Epoch 49/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0390 - accuracy: 0.8570 - val_loss: 0.0671 - val_mse: 0.0671 - val_mae: 0.0678 - val_accuracy: 0.8270\n",
      "Epoch 50/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0391 - accuracy: 0.8590 - val_loss: 0.0655 - val_mse: 0.0655 - val_mae: 0.0667 - val_accuracy: 0.8349\n",
      "Epoch 51/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0358 - accuracy: 0.8687 - val_loss: 0.0795 - val_mse: 0.0795 - val_mae: 0.0692 - val_accuracy: 0.8297\n",
      "Epoch 52/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0402 - accuracy: 0.8599 - val_loss: 0.0684 - val_mse: 0.0684 - val_mae: 0.0665 - val_accuracy: 0.8361\n",
      "Epoch 53/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0369 - accuracy: 0.8690 - val_loss: 0.0670 - val_mse: 0.0670 - val_mae: 0.0666 - val_accuracy: 0.8386\n",
      "Epoch 54/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0354 - accuracy: 0.8698 - val_loss: 0.0649 - val_mse: 0.0649 - val_mae: 0.0655 - val_accuracy: 0.8406\n",
      "Epoch 55/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0337 - accuracy: 0.8764 - val_loss: 0.0732 - val_mse: 0.0732 - val_mae: 0.0683 - val_accuracy: 0.8240\n",
      "Epoch 56/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0346 - accuracy: 0.8727 - val_loss: 0.0649 - val_mse: 0.0649 - val_mae: 0.0656 - val_accuracy: 0.8253\n",
      "Epoch 57/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0378 - accuracy: 0.8653 - val_loss: 0.0979 - val_mse: 0.0979 - val_mae: 0.1128 - val_accuracy: 0.7093\n",
      "Epoch 58/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0459 - accuracy: 0.8408 - val_loss: 0.0983 - val_mse: 0.0983 - val_mae: 0.0828 - val_accuracy: 0.7819\n",
      "Epoch 59/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0490 - accuracy: 0.8354 - val_loss: 0.0705 - val_mse: 0.0705 - val_mae: 0.0688 - val_accuracy: 0.8263\n",
      "Epoch 60/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0378 - accuracy: 0.8647 - val_loss: 0.0658 - val_mse: 0.0658 - val_mae: 0.0659 - val_accuracy: 0.8360\n",
      "Epoch 61/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0353 - accuracy: 0.8717 - val_loss: 0.0734 - val_mse: 0.0734 - val_mae: 0.0692 - val_accuracy: 0.8273\n",
      "Epoch 62/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0322 - accuracy: 0.8786 - val_loss: 0.0657 - val_mse: 0.0657 - val_mae: 0.0654 - val_accuracy: 0.8404\n",
      "Epoch 63/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0310 - accuracy: 0.8796 - val_loss: 0.0636 - val_mse: 0.0636 - val_mae: 0.0646 - val_accuracy: 0.8437\n",
      "Epoch 64/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0303 - accuracy: 0.8820 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.0661 - val_accuracy: 0.8256\n",
      "Epoch 65/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0324 - accuracy: 0.8798 - val_loss: 0.0694 - val_mse: 0.0694 - val_mae: 0.0676 - val_accuracy: 0.8241\n",
      "Epoch 66/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0430 - accuracy: 0.8550 - val_loss: 0.0682 - val_mse: 0.0682 - val_mae: 0.0660 - val_accuracy: 0.8341\n",
      "Epoch 67/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0360 - accuracy: 0.8665 - val_loss: 0.0664 - val_mse: 0.0664 - val_mae: 0.0637 - val_accuracy: 0.8377\n",
      "Epoch 68/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0337 - accuracy: 0.8783 - val_loss: 0.0642 - val_mse: 0.0642 - val_mae: 0.0641 - val_accuracy: 0.8426\n",
      "Epoch 69/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0326 - accuracy: 0.8802 - val_loss: 0.0634 - val_mse: 0.0634 - val_mae: 0.0636 - val_accuracy: 0.8450\n",
      "Epoch 70/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0282 - accuracy: 0.8878 - val_loss: 0.0624 - val_mse: 0.0624 - val_mae: 0.0633 - val_accuracy: 0.8461\n",
      "Epoch 71/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0288 - accuracy: 0.8900 - val_loss: 0.0699 - val_mse: 0.0699 - val_mae: 0.0667 - val_accuracy: 0.8313\n",
      "Epoch 72/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0318 - accuracy: 0.8787 - val_loss: 0.0679 - val_mse: 0.0679 - val_mae: 0.0654 - val_accuracy: 0.8284\n",
      "Epoch 73/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0461 - accuracy: 0.8450 - val_loss: 0.0876 - val_mse: 0.0876 - val_mae: 0.0674 - val_accuracy: 0.8366\n",
      "Epoch 74/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0332 - accuracy: 0.8750 - val_loss: 0.0675 - val_mse: 0.0675 - val_mae: 0.0653 - val_accuracy: 0.8244\n",
      "Epoch 75/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0291 - accuracy: 0.8890 - val_loss: 0.0676 - val_mse: 0.0676 - val_mae: 0.0628 - val_accuracy: 0.8506\n",
      "Epoch 76/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0331 - accuracy: 0.8758 - val_loss: 0.0667 - val_mse: 0.0667 - val_mae: 0.0704 - val_accuracy: 0.8319\n",
      "Epoch 77/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0360 - accuracy: 0.8659 - val_loss: 0.0664 - val_mse: 0.0664 - val_mae: 0.0645 - val_accuracy: 0.8421\n",
      "Epoch 78/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0350 - accuracy: 0.8769 - val_loss: 0.0692 - val_mse: 0.0692 - val_mae: 0.0760 - val_accuracy: 0.8063\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0365 - accuracy: 0.8643 - val_loss: 0.0719 - val_mse: 0.0719 - val_mae: 0.0883 - val_accuracy: 0.8094\n",
      "Epoch 80/150\n",
      "329/329 [==============================] - 18s 55ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0374 - accuracy: 0.8687 - val_loss: 0.0720 - val_mse: 0.0720 - val_mae: 0.0705 - val_accuracy: 0.8220\n",
      "Epoch 81/150\n",
      "329/329 [==============================] - 20s 60ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0346 - accuracy: 0.8732 - val_loss: 0.0618 - val_mse: 0.0618 - val_mae: 0.0649 - val_accuracy: 0.8416\n",
      "Epoch 82/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0328 - accuracy: 0.8775 - val_loss: 0.0782 - val_mse: 0.0782 - val_mae: 0.0713 - val_accuracy: 0.8360\n",
      "Epoch 83/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0303 - accuracy: 0.8836 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.0616 - val_accuracy: 0.8447\n",
      "Epoch 84/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0333 - accuracy: 0.8756 - val_loss: 0.0694 - val_mse: 0.0694 - val_mae: 0.0648 - val_accuracy: 0.8450\n",
      "Epoch 85/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0305 - accuracy: 0.8825 - val_loss: 0.0645 - val_mse: 0.0645 - val_mae: 0.0645 - val_accuracy: 0.8414\n",
      "Epoch 86/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0275 - accuracy: 0.8930 - val_loss: 0.0697 - val_mse: 0.0697 - val_mae: 0.0911 - val_accuracy: 0.7933\n",
      "Epoch 87/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0370 - accuracy: 0.8724 - val_loss: 0.0750 - val_mse: 0.0750 - val_mae: 0.0810 - val_accuracy: 0.8184\n",
      "Epoch 88/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0304 - accuracy: 0.8857 - val_loss: 0.0641 - val_mse: 0.0641 - val_mae: 0.0614 - val_accuracy: 0.8459\n",
      "Epoch 89/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0274 - accuracy: 0.8911 - val_loss: 0.0612 - val_mse: 0.0612 - val_mae: 0.0606 - val_accuracy: 0.8500\n",
      "Epoch 90/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0283 - accuracy: 0.8845 - val_loss: 0.0676 - val_mse: 0.0676 - val_mae: 0.0624 - val_accuracy: 0.8513\n",
      "Epoch 91/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0342 - accuracy: 0.8755 - val_loss: 0.0632 - val_mse: 0.0632 - val_mae: 0.0637 - val_accuracy: 0.8481\n",
      "Epoch 92/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0261 - accuracy: 0.8984 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.0615 - val_accuracy: 0.8437\n",
      "Epoch 93/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0263 - accuracy: 0.8958 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.0618 - val_accuracy: 0.8466\n",
      "Epoch 94/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0278 - accuracy: 0.8889 - val_loss: 0.0650 - val_mse: 0.0650 - val_mae: 0.0629 - val_accuracy: 0.8519\n",
      "Epoch 95/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0280 - accuracy: 0.8885 - val_loss: 0.0649 - val_mse: 0.0649 - val_mae: 0.0617 - val_accuracy: 0.8393\n",
      "Epoch 96/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0314 - accuracy: 0.8843 - val_loss: 0.0895 - val_mse: 0.0895 - val_mae: 0.0701 - val_accuracy: 0.8236\n",
      "Epoch 97/150\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0435 - accuracy: 0.8531 - val_loss: 0.0691 - val_mse: 0.0691 - val_mae: 0.0699 - val_accuracy: 0.8199\n",
      "Epoch 98/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0350 - accuracy: 0.8759 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.0751 - val_accuracy: 0.8080\n",
      "Epoch 99/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0372 - accuracy: 0.8676 - val_loss: 0.1009 - val_mse: 0.1009 - val_mae: 0.0657 - val_accuracy: 0.8349\n",
      "Epoch 100/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0372 - accuracy: 0.8665 - val_loss: 0.0634 - val_mse: 0.0634 - val_mae: 0.0614 - val_accuracy: 0.8503\n",
      "Epoch 101/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0260 - accuracy: 0.8954 - val_loss: 0.0618 - val_mse: 0.0618 - val_mae: 0.0642 - val_accuracy: 0.8363\n",
      "Epoch 102/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0241 - accuracy: 0.9005 - val_loss: 0.0611 - val_mse: 0.0611 - val_mae: 0.0589 - val_accuracy: 0.8537\n",
      "Epoch 103/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0239 - accuracy: 0.9010 - val_loss: 0.0616 - val_mse: 0.0616 - val_mae: 0.0593 - val_accuracy: 0.8541\n",
      "Epoch 104/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0247 - accuracy: 0.9002 - val_loss: 0.0624 - val_mse: 0.0624 - val_mae: 0.0612 - val_accuracy: 0.8564\n",
      "Epoch 105/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0249 - accuracy: 0.8993 - val_loss: 0.0678 - val_mse: 0.0678 - val_mae: 0.0639 - val_accuracy: 0.8449\n",
      "Epoch 106/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0273 - accuracy: 0.8932 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.0621 - val_accuracy: 0.8281\n",
      "Epoch 107/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0263 - accuracy: 0.8928 - val_loss: 0.0664 - val_mse: 0.0664 - val_mae: 0.0617 - val_accuracy: 0.8473\n",
      "Epoch 108/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0335 - accuracy: 0.8740 - val_loss: 0.0701 - val_mse: 0.0701 - val_mae: 0.0632 - val_accuracy: 0.8350\n",
      "Epoch 109/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0270 - accuracy: 0.8919 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.0633 - val_accuracy: 0.8439\n",
      "Epoch 110/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0329 - accuracy: 0.8840 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.0611 - val_accuracy: 0.8419\n",
      "Epoch 111/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0259 - accuracy: 0.8964 - val_loss: 0.0663 - val_mse: 0.0663 - val_mae: 0.0595 - val_accuracy: 0.8551\n",
      "Epoch 112/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0274 - accuracy: 0.8899 - val_loss: 0.0632 - val_mse: 0.0632 - val_mae: 0.0601 - val_accuracy: 0.8484\n",
      "Epoch 113/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0255 - accuracy: 0.8960 - val_loss: 0.0637 - val_mse: 0.0637 - val_mae: 0.0596 - val_accuracy: 0.8520\n",
      "Epoch 114/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0242 - accuracy: 0.9026 - val_loss: 0.0630 - val_mse: 0.0630 - val_mae: 0.0596 - val_accuracy: 0.8489\n",
      "Epoch 115/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0254 - accuracy: 0.8920 - val_loss: 0.0640 - val_mse: 0.0640 - val_mae: 0.0652 - val_accuracy: 0.8396\n",
      "Epoch 116/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0348 - accuracy: 0.8744 - val_loss: 0.0731 - val_mse: 0.0731 - val_mae: 0.0673 - val_accuracy: 0.8299\n",
      "Epoch 117/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0328 - accuracy: 0.8747 - val_loss: 0.0688 - val_mse: 0.0688 - val_mae: 0.0661 - val_accuracy: 0.8326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0274 - accuracy: 0.8923 - val_loss: 0.0688 - val_mse: 0.0688 - val_mae: 0.0597 - val_accuracy: 0.8569\n",
      "Epoch 119/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0293 - accuracy: 0.8885 - val_loss: 0.0650 - val_mse: 0.0650 - val_mae: 0.0603 - val_accuracy: 0.8540\n",
      "Epoch 120/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0233 - accuracy: 0.9024 - val_loss: 0.0628 - val_mse: 0.0628 - val_mae: 0.0596 - val_accuracy: 0.8296\n",
      "Epoch 121/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0243 - accuracy: 0.9019 - val_loss: 0.0637 - val_mse: 0.0637 - val_mae: 0.0582 - val_accuracy: 0.8383\n",
      "Epoch 122/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0241 - accuracy: 0.9015 - val_loss: 0.0636 - val_mse: 0.0636 - val_mae: 0.0606 - val_accuracy: 0.8440\n",
      "Epoch 123/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0319 - accuracy: 0.8843 - val_loss: 0.0710 - val_mse: 0.0710 - val_mae: 0.0622 - val_accuracy: 0.8446\n",
      "Epoch 124/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0301 - accuracy: 0.8840 - val_loss: 0.0660 - val_mse: 0.0660 - val_mae: 0.0585 - val_accuracy: 0.8474\n",
      "Epoch 125/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0300 - accuracy: 0.8853 - val_loss: 0.0684 - val_mse: 0.0684 - val_mae: 0.0612 - val_accuracy: 0.8531\n",
      "Epoch 126/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0309 - accuracy: 0.8826 - val_loss: 0.0705 - val_mse: 0.0705 - val_mae: 0.0617 - val_accuracy: 0.8444\n",
      "Epoch 127/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0276 - accuracy: 0.8933 - val_loss: 0.0662 - val_mse: 0.0662 - val_mae: 0.0595 - val_accuracy: 0.8450\n",
      "Epoch 128/150\n",
      "329/329 [==============================] - 18s 53ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0244 - accuracy: 0.9041 - val_loss: 0.0671 - val_mse: 0.0671 - val_mae: 0.0606 - val_accuracy: 0.8436\n",
      "Epoch 129/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0282 - accuracy: 0.8914 - val_loss: 0.0729 - val_mse: 0.0729 - val_mae: 0.0637 - val_accuracy: 0.8404\n",
      "Epoch 130/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0342 - accuracy: 0.8746 - val_loss: 0.0694 - val_mse: 0.0694 - val_mae: 0.0621 - val_accuracy: 0.8463\n",
      "Epoch 131/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0280 - accuracy: 0.8909 - val_loss: 0.0681 - val_mse: 0.0681 - val_mae: 0.0587 - val_accuracy: 0.8574\n",
      "Epoch 132/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0277 - accuracy: 0.8901 - val_loss: 0.0647 - val_mse: 0.0647 - val_mae: 0.0593 - val_accuracy: 0.8551\n",
      "Epoch 133/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0263 - accuracy: 0.8960 - val_loss: 0.0659 - val_mse: 0.0659 - val_mae: 0.0586 - val_accuracy: 0.8557\n",
      "Epoch 134/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0275 - accuracy: 0.8950 - val_loss: 0.0702 - val_mse: 0.0702 - val_mae: 0.0596 - val_accuracy: 0.8490\n",
      "Epoch 135/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0299 - accuracy: 0.8824 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.0580 - val_accuracy: 0.8531\n",
      "Epoch 136/150\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0263 - accuracy: 0.8950 - val_loss: 0.0660 - val_mse: 0.0660 - val_mae: 0.0589 - val_accuracy: 0.8327\n",
      "Epoch 137/150\n",
      "329/329 [==============================] - 20s 59ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0242 - accuracy: 0.9005 - val_loss: 0.0663 - val_mse: 0.0663 - val_mae: 0.0575 - val_accuracy: 0.8607\n",
      "Epoch 138/150\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0223 - accuracy: 0.9074 - val_loss: 0.0643 - val_mse: 0.0643 - val_mae: 0.0579 - val_accuracy: 0.8327\n",
      "Epoch 139/150\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0283 - accuracy: 0.8878 - val_loss: 0.0752 - val_mse: 0.0752 - val_mae: 0.0614 - val_accuracy: 0.8436\n",
      "Epoch 140/150\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0298 - accuracy: 0.8852 - val_loss: 0.0771 - val_mse: 0.0771 - val_mae: 0.0623 - val_accuracy: 0.8484\n",
      "Epoch 141/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0259 - accuracy: 0.8930 - val_loss: 0.0680 - val_mse: 0.0680 - val_mae: 0.0727 - val_accuracy: 0.8449\n",
      "Epoch 142/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0263 - accuracy: 0.8944 - val_loss: 0.0637 - val_mse: 0.0637 - val_mae: 0.0573 - val_accuracy: 0.8641\n",
      "Epoch 143/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0217 - accuracy: 0.9083 - val_loss: 0.0671 - val_mse: 0.0671 - val_mae: 0.0643 - val_accuracy: 0.8336\n",
      "Epoch 144/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0288 - accuracy: 0.8881 - val_loss: 0.0651 - val_mse: 0.0651 - val_mae: 0.0607 - val_accuracy: 0.8094\n",
      "Epoch 145/150\n",
      "329/329 [==============================] - 15s 47ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0301 - accuracy: 0.8853 - val_loss: 0.0733 - val_mse: 0.0733 - val_mae: 0.0630 - val_accuracy: 0.8396\n",
      "Epoch 146/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0322 - accuracy: 0.8803 - val_loss: 0.0682 - val_mse: 0.0682 - val_mae: 0.0590 - val_accuracy: 0.8511\n",
      "Epoch 147/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0280 - accuracy: 0.8905 - val_loss: 0.0649 - val_mse: 0.0649 - val_mae: 0.0577 - val_accuracy: 0.8576\n",
      "Epoch 148/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0233 - accuracy: 0.9041 - val_loss: 0.0664 - val_mse: 0.0664 - val_mae: 0.0698 - val_accuracy: 0.8366\n",
      "Epoch 149/150\n",
      "329/329 [==============================] - 15s 47ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0240 - accuracy: 0.9039 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.0576 - val_accuracy: 0.8594\n",
      "Epoch 150/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0287 - accuracy: 0.8906 - val_loss: 0.0700 - val_mse: 0.0700 - val_mae: 0.0697 - val_accuracy: 0.8236\n",
      "[INFO] evaluate the model...\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0700 - mse: 0.0700 - mae: 0.0697 - accuracy: 0.8236\n",
      "[INFO] making predictions on test data...\n",
      "219/219 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/150\n",
      "329/329 [==============================] - 17s 49ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0282 - accuracy: 0.8878 - val_loss: 0.0747 - val_mse: 0.0747 - val_mae: 0.0694 - val_accuracy: 0.8257\n",
      "Epoch 2/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0280 - accuracy: 0.8897 - val_loss: 0.0663 - val_mse: 0.0663 - val_mae: 0.0588 - val_accuracy: 0.8613\n",
      "Epoch 3/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0255 - accuracy: 0.8979 - val_loss: 0.0743 - val_mse: 0.0743 - val_mae: 0.0658 - val_accuracy: 0.8143\n",
      "Epoch 4/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0324 - accuracy: 0.8737 - val_loss: 0.0643 - val_mse: 0.0643 - val_mae: 0.0602 - val_accuracy: 0.8574\n",
      "Epoch 5/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0278 - accuracy: 0.8941 - val_loss: 0.0668 - val_mse: 0.0668 - val_mae: 0.0613 - val_accuracy: 0.8441\n",
      "Epoch 6/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0240 - accuracy: 0.9000 - val_loss: 0.0647 - val_mse: 0.0647 - val_mae: 0.0574 - val_accuracy: 0.8541\n",
      "Epoch 7/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0219 - accuracy: 0.9065 - val_loss: 0.0644 - val_mse: 0.0644 - val_mae: 0.0598 - val_accuracy: 0.8539\n",
      "Epoch 8/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0216 - accuracy: 0.9076 - val_loss: 0.0647 - val_mse: 0.0647 - val_mae: 0.0571 - val_accuracy: 0.8441\n",
      "Epoch 9/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0234 - accuracy: 0.9035 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.0640 - val_accuracy: 0.8443\n",
      "Epoch 10/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0274 - accuracy: 0.8899 - val_loss: 0.0692 - val_mse: 0.0692 - val_mae: 0.0590 - val_accuracy: 0.8560\n",
      "Epoch 11/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0295 - accuracy: 0.8883 - val_loss: 0.0704 - val_mse: 0.0704 - val_mae: 0.0591 - val_accuracy: 0.8449\n",
      "Epoch 12/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0343 - accuracy: 0.8674 - val_loss: 0.0709 - val_mse: 0.0709 - val_mae: 0.0620 - val_accuracy: 0.8420\n",
      "Epoch 13/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0297 - accuracy: 0.8861 - val_loss: 0.0659 - val_mse: 0.0659 - val_mae: 0.0582 - val_accuracy: 0.8543\n",
      "Epoch 14/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0217 - accuracy: 0.9085 - val_loss: 0.0656 - val_mse: 0.0656 - val_mae: 0.0572 - val_accuracy: 0.8654\n",
      "Epoch 15/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0215 - accuracy: 0.9092 - val_loss: 0.0654 - val_mse: 0.0654 - val_mae: 0.0576 - val_accuracy: 0.8577\n",
      "Epoch 16/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0226 - accuracy: 0.9064 - val_loss: 0.0661 - val_mse: 0.0661 - val_mae: 0.0577 - val_accuracy: 0.8584\n",
      "Epoch 17/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - accuracy: 0.9084 - val_loss: 0.0654 - val_mse: 0.0654 - val_mae: 0.0567 - val_accuracy: 0.8580\n",
      "Epoch 18/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0227 - accuracy: 0.9079 - val_loss: 0.0712 - val_mse: 0.0712 - val_mae: 0.0586 - val_accuracy: 0.8596\n",
      "Epoch 19/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0289 - accuracy: 0.8896 - val_loss: 0.0686 - val_mse: 0.0686 - val_mae: 0.0586 - val_accuracy: 0.8503\n",
      "Epoch 20/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0294 - accuracy: 0.8884 - val_loss: 0.0717 - val_mse: 0.0717 - val_mae: 0.0604 - val_accuracy: 0.8500\n",
      "Epoch 21/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0267 - accuracy: 0.8937 - val_loss: 0.0697 - val_mse: 0.0697 - val_mae: 0.0643 - val_accuracy: 0.8417\n",
      "Epoch 22/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0314 - accuracy: 0.8808 - val_loss: 0.0711 - val_mse: 0.0711 - val_mae: 0.0617 - val_accuracy: 0.8440\n",
      "Epoch 23/150\n",
      "329/329 [==============================] - 21s 63ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0256 - accuracy: 0.8977 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.0573 - val_accuracy: 0.8483\n",
      "Epoch 24/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0238 - accuracy: 0.9037 - val_loss: 0.0667 - val_mse: 0.0667 - val_mae: 0.0580 - val_accuracy: 0.8607\n",
      "Epoch 25/150\n",
      "329/329 [==============================] - 20s 61ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0228 - accuracy: 0.9080 - val_loss: 0.0741 - val_mse: 0.0741 - val_mae: 0.0595 - val_accuracy: 0.8451\n",
      "Epoch 26/150\n",
      "329/329 [==============================] - 19s 59ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0305 - accuracy: 0.8827 - val_loss: 0.0916 - val_mse: 0.0916 - val_mae: 0.0807 - val_accuracy: 0.7547\n",
      "Epoch 27/150\n",
      "329/329 [==============================] - 19s 58ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0331 - accuracy: 0.8818 - val_loss: 0.0706 - val_mse: 0.0706 - val_mae: 0.0585 - val_accuracy: 0.8554\n",
      "Epoch 28/150\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0268 - accuracy: 0.8932 - val_loss: 0.0686 - val_mse: 0.0686 - val_mae: 0.0577 - val_accuracy: 0.8471\n",
      "Epoch 29/150\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0221 - accuracy: 0.9085 - val_loss: 0.0710 - val_mse: 0.0710 - val_mae: 0.0686 - val_accuracy: 0.8257\n",
      "Epoch 30/150\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0294 - accuracy: 0.8859 - val_loss: 0.0681 - val_mse: 0.0681 - val_mae: 0.0605 - val_accuracy: 0.8486\n",
      "Epoch 31/150\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0270 - accuracy: 0.8957 - val_loss: 0.0656 - val_mse: 0.0656 - val_mae: 0.0564 - val_accuracy: 0.8626\n",
      "Epoch 32/150\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0203 - accuracy: 0.9130 - val_loss: 0.0645 - val_mse: 0.0645 - val_mae: 0.0560 - val_accuracy: 0.8561\n",
      "Epoch 33/150\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0221 - accuracy: 0.9081 - val_loss: 0.0676 - val_mse: 0.0676 - val_mae: 0.0565 - val_accuracy: 0.8564\n",
      "Epoch 34/150\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0230 - accuracy: 0.9034 - val_loss: 0.0685 - val_mse: 0.0685 - val_mae: 0.0578 - val_accuracy: 0.8570\n",
      "Epoch 35/150\n",
      "329/329 [==============================] - 18s 55ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0258 - accuracy: 0.8970 - val_loss: 0.0757 - val_mse: 0.0757 - val_mae: 0.0713 - val_accuracy: 0.8196\n",
      "Epoch 36/150\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0291 - accuracy: 0.8919 - val_loss: 0.0677 - val_mse: 0.0677 - val_mae: 0.0708 - val_accuracy: 0.7904\n",
      "Epoch 37/150\n",
      "329/329 [==============================] - 18s 55ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0258 - accuracy: 0.8975 - val_loss: 0.0683 - val_mse: 0.0683 - val_mae: 0.0605 - val_accuracy: 0.8371\n",
      "Epoch 38/150\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0216 - accuracy: 0.9081 - val_loss: 0.0654 - val_mse: 0.0654 - val_mae: 0.0575 - val_accuracy: 0.8536\n",
      "Epoch 39/150\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0248 - accuracy: 0.8985 - val_loss: 0.0740 - val_mse: 0.0740 - val_mae: 0.0600 - val_accuracy: 0.8569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0261 - accuracy: 0.8950 - val_loss: 0.0717 - val_mse: 0.0717 - val_mae: 0.0591 - val_accuracy: 0.8551\n",
      "Epoch 41/150\n",
      "329/329 [==============================] - 18s 53ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0244 - accuracy: 0.8987 - val_loss: 0.0633 - val_mse: 0.0633 - val_mae: 0.0599 - val_accuracy: 0.8511\n",
      "Epoch 42/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0247 - accuracy: 0.8989 - val_loss: 0.0653 - val_mse: 0.0653 - val_mae: 0.0583 - val_accuracy: 0.8557\n",
      "Epoch 43/150\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0212 - accuracy: 0.9127 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.0567 - val_accuracy: 0.8537\n",
      "Epoch 44/150\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0221 - accuracy: 0.9062 - val_loss: 0.0720 - val_mse: 0.0720 - val_mae: 0.0619 - val_accuracy: 0.8621\n",
      "Epoch 45/150\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0253 - accuracy: 0.8993 - val_loss: 0.0847 - val_mse: 0.0847 - val_mae: 0.0626 - val_accuracy: 0.8434\n",
      "Epoch 46/150\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0344 - accuracy: 0.8743 - val_loss: 0.0679 - val_mse: 0.0679 - val_mae: 0.0615 - val_accuracy: 0.8184\n",
      "Epoch 47/150\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0228 - accuracy: 0.9020 - val_loss: 0.0795 - val_mse: 0.0795 - val_mae: 0.0728 - val_accuracy: 0.8331\n",
      "Epoch 48/150\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0272 - accuracy: 0.8946 - val_loss: 0.0687 - val_mse: 0.0687 - val_mae: 0.0630 - val_accuracy: 0.8450\n",
      "Epoch 49/150\n",
      "329/329 [==============================] - 18s 55ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0276 - accuracy: 0.8911 - val_loss: 0.0684 - val_mse: 0.0684 - val_mae: 0.0584 - val_accuracy: 0.8544\n",
      "Epoch 50/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0219 - accuracy: 0.9096 - val_loss: 0.0696 - val_mse: 0.0696 - val_mae: 0.0597 - val_accuracy: 0.8434\n",
      "Epoch 51/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0226 - accuracy: 0.9062 - val_loss: 0.0678 - val_mse: 0.0678 - val_mae: 0.0561 - val_accuracy: 0.8674\n",
      "Epoch 52/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0303 - accuracy: 0.8889 - val_loss: 0.0768 - val_mse: 0.0768 - val_mae: 0.0594 - val_accuracy: 0.8343\n",
      "Epoch 53/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0260 - accuracy: 0.8970 - val_loss: 0.0723 - val_mse: 0.0723 - val_mae: 0.0574 - val_accuracy: 0.8531\n",
      "Epoch 54/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0258 - accuracy: 0.9013 - val_loss: 0.0687 - val_mse: 0.0687 - val_mae: 0.0572 - val_accuracy: 0.8559\n",
      "Epoch 55/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0251 - accuracy: 0.8960 - val_loss: 0.0701 - val_mse: 0.0701 - val_mae: 0.0595 - val_accuracy: 0.8509\n",
      "Epoch 56/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0237 - accuracy: 0.9015 - val_loss: 0.0659 - val_mse: 0.0659 - val_mae: 0.0568 - val_accuracy: 0.8621\n",
      "Epoch 57/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0236 - accuracy: 0.9029 - val_loss: 0.0685 - val_mse: 0.0685 - val_mae: 0.0574 - val_accuracy: 0.8516\n",
      "Epoch 58/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0228 - accuracy: 0.9055 - val_loss: 0.0690 - val_mse: 0.0690 - val_mae: 0.0582 - val_accuracy: 0.8499\n",
      "Epoch 59/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0227 - accuracy: 0.9039 - val_loss: 0.0655 - val_mse: 0.0655 - val_mae: 0.0555 - val_accuracy: 0.8620\n",
      "Epoch 60/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0225 - accuracy: 0.9039 - val_loss: 0.0703 - val_mse: 0.0703 - val_mae: 0.0638 - val_accuracy: 0.8491\n",
      "Epoch 61/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0229 - accuracy: 0.9038 - val_loss: 0.0700 - val_mse: 0.0700 - val_mae: 0.0630 - val_accuracy: 0.8446\n",
      "Epoch 62/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0219 - accuracy: 0.9079 - val_loss: 0.0734 - val_mse: 0.0734 - val_mae: 0.0608 - val_accuracy: 0.8531\n",
      "Epoch 63/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0267 - accuracy: 0.8922 - val_loss: 0.0755 - val_mse: 0.0755 - val_mae: 0.0829 - val_accuracy: 0.8179\n",
      "Epoch 64/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0309 - accuracy: 0.8785 - val_loss: 0.0716 - val_mse: 0.0716 - val_mae: 0.0671 - val_accuracy: 0.7937\n",
      "Epoch 65/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0276 - accuracy: 0.8930 - val_loss: 0.0748 - val_mse: 0.0748 - val_mae: 0.0656 - val_accuracy: 0.8431\n",
      "Epoch 66/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0238 - accuracy: 0.9011 - val_loss: 0.0753 - val_mse: 0.0753 - val_mae: 0.0652 - val_accuracy: 0.8341\n",
      "Epoch 67/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0245 - accuracy: 0.8976 - val_loss: 0.0687 - val_mse: 0.0687 - val_mae: 0.0598 - val_accuracy: 0.8569\n",
      "Epoch 68/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0257 - accuracy: 0.9021 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.0622 - val_accuracy: 0.8459\n",
      "Epoch 69/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0281 - accuracy: 0.8917 - val_loss: 0.0715 - val_mse: 0.0715 - val_mae: 0.0631 - val_accuracy: 0.8381\n",
      "Epoch 70/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0229 - accuracy: 0.9060 - val_loss: 0.0687 - val_mse: 0.0687 - val_mae: 0.0602 - val_accuracy: 0.8493\n",
      "Epoch 71/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0229 - accuracy: 0.9053 - val_loss: 0.0649 - val_mse: 0.0649 - val_mae: 0.0570 - val_accuracy: 0.8523\n",
      "Epoch 72/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0236 - accuracy: 0.9049 - val_loss: 0.0685 - val_mse: 0.0685 - val_mae: 0.0572 - val_accuracy: 0.8514\n",
      "Epoch 73/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0222 - accuracy: 0.9071 - val_loss: 0.0655 - val_mse: 0.0655 - val_mae: 0.0554 - val_accuracy: 0.8563\n",
      "Epoch 74/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0209 - accuracy: 0.9124 - val_loss: 0.0686 - val_mse: 0.0686 - val_mae: 0.0590 - val_accuracy: 0.8494\n",
      "Epoch 75/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0218 - accuracy: 0.9126 - val_loss: 0.0678 - val_mse: 0.0678 - val_mae: 0.0552 - val_accuracy: 0.8664\n",
      "Epoch 76/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0240 - accuracy: 0.9020 - val_loss: 0.0775 - val_mse: 0.0775 - val_mae: 0.0783 - val_accuracy: 0.8056\n",
      "Epoch 77/150\n",
      "329/329 [==============================] - 3642s 11s/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0285 - accuracy: 0.8886 - val_loss: 0.0730 - val_mse: 0.0730 - val_mae: 0.0590 - val_accuracy: 0.8430\n",
      "Epoch 78/150\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0224 - accuracy: 0.9041 - val_loss: 0.0703 - val_mse: 0.0703 - val_mae: 0.0561 - val_accuracy: 0.8597\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0212 - accuracy: 0.9097 - val_loss: 0.0713 - val_mse: 0.0713 - val_mae: 0.0573 - val_accuracy: 0.8524\n",
      "Epoch 80/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0306 - accuracy: 0.8876 - val_loss: 0.0712 - val_mse: 0.0712 - val_mae: 0.0615 - val_accuracy: 0.8403\n",
      "Epoch 81/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0256 - accuracy: 0.8959 - val_loss: 0.0639 - val_mse: 0.0639 - val_mae: 0.0559 - val_accuracy: 0.8449\n",
      "Epoch 82/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 9.7451e-04 - mse: 9.7451e-04 - mae: 0.0195 - accuracy: 0.9133 - val_loss: 0.0651 - val_mse: 0.0651 - val_mae: 0.0559 - val_accuracy: 0.8563\n",
      "Epoch 83/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 9.6962e-04 - mse: 9.6962e-04 - mae: 0.0192 - accuracy: 0.9128 - val_loss: 0.0708 - val_mse: 0.0708 - val_mae: 0.0600 - val_accuracy: 0.8464\n",
      "Epoch 84/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0226 - accuracy: 0.9027 - val_loss: 0.0735 - val_mse: 0.0735 - val_mae: 0.0649 - val_accuracy: 0.8404\n",
      "Epoch 85/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0227 - accuracy: 0.9040 - val_loss: 0.0722 - val_mse: 0.0722 - val_mae: 0.0778 - val_accuracy: 0.8171\n",
      "Epoch 86/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0256 - accuracy: 0.8901 - val_loss: 0.0726 - val_mse: 0.0726 - val_mae: 0.0613 - val_accuracy: 0.8273\n",
      "Epoch 87/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0269 - accuracy: 0.8902 - val_loss: 0.0659 - val_mse: 0.0659 - val_mae: 0.0564 - val_accuracy: 0.8563\n",
      "Epoch 88/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0230 - accuracy: 0.9041 - val_loss: 0.0728 - val_mse: 0.0728 - val_mae: 0.0697 - val_accuracy: 0.8301\n",
      "Epoch 89/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0289 - accuracy: 0.8892 - val_loss: 0.0656 - val_mse: 0.0656 - val_mae: 0.0556 - val_accuracy: 0.8563\n",
      "Epoch 90/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0246 - accuracy: 0.9001 - val_loss: 0.0681 - val_mse: 0.0681 - val_mae: 0.0557 - val_accuracy: 0.8614\n",
      "Epoch 91/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - accuracy: 0.9092 - val_loss: 0.0681 - val_mse: 0.0681 - val_mae: 0.0553 - val_accuracy: 0.8603\n",
      "Epoch 92/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 9.6055e-04 - mse: 9.6055e-04 - mae: 0.0195 - accuracy: 0.9143 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.0563 - val_accuracy: 0.8624\n",
      "Epoch 93/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0206 - accuracy: 0.9096 - val_loss: 0.0657 - val_mse: 0.0657 - val_mae: 0.0550 - val_accuracy: 0.8613\n",
      "Epoch 94/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0296 - accuracy: 0.8849 - val_loss: 0.0671 - val_mse: 0.0671 - val_mae: 0.0577 - val_accuracy: 0.8554\n",
      "Epoch 95/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0268 - accuracy: 0.8942 - val_loss: 0.0677 - val_mse: 0.0677 - val_mae: 0.0581 - val_accuracy: 0.8424\n",
      "Epoch 96/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0252 - accuracy: 0.8984 - val_loss: 0.0715 - val_mse: 0.0715 - val_mae: 0.0670 - val_accuracy: 0.8339\n",
      "Epoch 97/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0290 - accuracy: 0.8852 - val_loss: 0.0641 - val_mse: 0.0641 - val_mae: 0.0579 - val_accuracy: 0.8574\n",
      "Epoch 98/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0234 - accuracy: 0.9045 - val_loss: 0.0814 - val_mse: 0.0814 - val_mae: 0.0870 - val_accuracy: 0.7843\n",
      "Epoch 99/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0270 - accuracy: 0.8942 - val_loss: 0.0704 - val_mse: 0.0704 - val_mae: 0.0743 - val_accuracy: 0.8476\n",
      "Epoch 100/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0257 - accuracy: 0.8990 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.0570 - val_accuracy: 0.8600\n",
      "Epoch 101/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0203 - accuracy: 0.9119 - val_loss: 0.0680 - val_mse: 0.0680 - val_mae: 0.0563 - val_accuracy: 0.8329\n",
      "Epoch 102/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0199 - accuracy: 0.9085 - val_loss: 0.0674 - val_mse: 0.0674 - val_mae: 0.0563 - val_accuracy: 0.8603\n",
      "Epoch 103/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0215 - accuracy: 0.9069 - val_loss: 0.0673 - val_mse: 0.0673 - val_mae: 0.0617 - val_accuracy: 0.8246\n",
      "Epoch 104/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0226 - accuracy: 0.9060 - val_loss: 0.0725 - val_mse: 0.0725 - val_mae: 0.0560 - val_accuracy: 0.8634\n",
      "Epoch 105/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0265 - accuracy: 0.8925 - val_loss: 0.0709 - val_mse: 0.0709 - val_mae: 0.0560 - val_accuracy: 0.8577\n",
      "Epoch 106/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0271 - accuracy: 0.8948 - val_loss: 0.0678 - val_mse: 0.0678 - val_mae: 0.0559 - val_accuracy: 0.8626\n",
      "Epoch 107/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0240 - accuracy: 0.8956 - val_loss: 0.0715 - val_mse: 0.0715 - val_mae: 0.0703 - val_accuracy: 0.8296\n",
      "Epoch 108/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0257 - accuracy: 0.8997 - val_loss: 0.0665 - val_mse: 0.0665 - val_mae: 0.0638 - val_accuracy: 0.8444\n",
      "Epoch 109/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0296 - accuracy: 0.8903 - val_loss: 0.0658 - val_mse: 0.0658 - val_mae: 0.0557 - val_accuracy: 0.8461\n",
      "Epoch 110/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0204 - accuracy: 0.9120 - val_loss: 0.0684 - val_mse: 0.0684 - val_mae: 0.0562 - val_accuracy: 0.8530\n",
      "Epoch 111/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 9.3796e-04 - mse: 9.3796e-04 - mae: 0.0189 - accuracy: 0.9175 - val_loss: 0.0671 - val_mse: 0.0671 - val_mae: 0.0545 - val_accuracy: 0.8627\n",
      "Epoch 112/150\n",
      "329/329 [==============================] - 15s 47ms/step - loss: 9.9711e-04 - mse: 9.9711e-04 - mae: 0.0193 - accuracy: 0.9139 - val_loss: 0.0701 - val_mse: 0.0701 - val_mae: 0.0597 - val_accuracy: 0.8561\n",
      "Epoch 113/150\n",
      "329/329 [==============================] - 15s 47ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0261 - accuracy: 0.8948 - val_loss: 0.0733 - val_mse: 0.0733 - val_mae: 0.0578 - val_accuracy: 0.8514\n",
      "Epoch 114/150\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0230 - accuracy: 0.9025 - val_loss: 0.0743 - val_mse: 0.0743 - val_mae: 0.0820 - val_accuracy: 0.8507\n",
      "Epoch 115/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0287 - accuracy: 0.8891 - val_loss: 0.0738 - val_mse: 0.0738 - val_mae: 0.0594 - val_accuracy: 0.8580\n",
      "Epoch 116/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0253 - accuracy: 0.9023 - val_loss: 0.0745 - val_mse: 0.0745 - val_mae: 0.0604 - val_accuracy: 0.8599\n",
      "Epoch 117/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0197 - accuracy: 0.9146 - val_loss: 0.0703 - val_mse: 0.0703 - val_mae: 0.0571 - val_accuracy: 0.8524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 9.5644e-04 - mse: 9.5644e-04 - mae: 0.0190 - accuracy: 0.9139 - val_loss: 0.0685 - val_mse: 0.0685 - val_mae: 0.0558 - val_accuracy: 0.8646\n",
      "Epoch 119/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0196 - accuracy: 0.9115 - val_loss: 0.0662 - val_mse: 0.0662 - val_mae: 0.0574 - val_accuracy: 0.8527\n",
      "Epoch 120/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - accuracy: 0.9158 - val_loss: 0.0676 - val_mse: 0.0676 - val_mae: 0.0549 - val_accuracy: 0.8637\n",
      "Epoch 121/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 9.7290e-04 - mse: 9.7290e-04 - mae: 0.0194 - accuracy: 0.9128 - val_loss: 0.0686 - val_mse: 0.0686 - val_mae: 0.0558 - val_accuracy: 0.8524\n",
      "Epoch 122/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0285 - accuracy: 0.8876 - val_loss: 0.0794 - val_mse: 0.0794 - val_mae: 0.0624 - val_accuracy: 0.8493\n",
      "Epoch 123/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0315 - accuracy: 0.8814 - val_loss: 0.0706 - val_mse: 0.0706 - val_mae: 0.0603 - val_accuracy: 0.8363\n",
      "Epoch 124/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0275 - accuracy: 0.8891 - val_loss: 0.0713 - val_mse: 0.0713 - val_mae: 0.0574 - val_accuracy: 0.8523\n",
      "Epoch 125/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0219 - accuracy: 0.9051 - val_loss: 0.0695 - val_mse: 0.0695 - val_mae: 0.0559 - val_accuracy: 0.8590\n",
      "Epoch 126/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0236 - accuracy: 0.9003 - val_loss: 0.0718 - val_mse: 0.0718 - val_mae: 0.0574 - val_accuracy: 0.8446\n",
      "Epoch 127/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0212 - accuracy: 0.9090 - val_loss: 0.0668 - val_mse: 0.0668 - val_mae: 0.0569 - val_accuracy: 0.8531\n",
      "Epoch 128/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0240 - accuracy: 0.9044 - val_loss: 0.0693 - val_mse: 0.0693 - val_mae: 0.0583 - val_accuracy: 0.8433\n",
      "Epoch 129/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0241 - accuracy: 0.9019 - val_loss: 0.0670 - val_mse: 0.0670 - val_mae: 0.0569 - val_accuracy: 0.8207\n",
      "Epoch 130/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0241 - accuracy: 0.8986 - val_loss: 0.0705 - val_mse: 0.0705 - val_mae: 0.0604 - val_accuracy: 0.8464\n",
      "Epoch 131/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0213 - accuracy: 0.9064 - val_loss: 0.0735 - val_mse: 0.0735 - val_mae: 0.0558 - val_accuracy: 0.8543\n",
      "Epoch 132/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0212 - accuracy: 0.9088 - val_loss: 0.0710 - val_mse: 0.0710 - val_mae: 0.0604 - val_accuracy: 0.8417\n",
      "Epoch 133/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0261 - accuracy: 0.8953 - val_loss: 0.0685 - val_mse: 0.0685 - val_mae: 0.0561 - val_accuracy: 0.8641\n",
      "Epoch 134/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0217 - accuracy: 0.9074 - val_loss: 0.0685 - val_mse: 0.0685 - val_mae: 0.0592 - val_accuracy: 0.8590\n",
      "Epoch 135/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0204 - accuracy: 0.9107 - val_loss: 0.0694 - val_mse: 0.0694 - val_mae: 0.0550 - val_accuracy: 0.8626\n",
      "Epoch 136/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0202 - accuracy: 0.9101 - val_loss: 0.0707 - val_mse: 0.0707 - val_mae: 0.0571 - val_accuracy: 0.8581\n",
      "Epoch 137/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0257 - accuracy: 0.8965 - val_loss: 0.0683 - val_mse: 0.0683 - val_mae: 0.0576 - val_accuracy: 0.8561\n",
      "Epoch 138/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0208 - accuracy: 0.9090 - val_loss: 0.0757 - val_mse: 0.0757 - val_mae: 0.0636 - val_accuracy: 0.8481\n",
      "Epoch 139/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0240 - accuracy: 0.9053 - val_loss: 0.0723 - val_mse: 0.0723 - val_mae: 0.0606 - val_accuracy: 0.8473\n",
      "Epoch 140/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0235 - accuracy: 0.9042 - val_loss: 0.0703 - val_mse: 0.0703 - val_mae: 0.0593 - val_accuracy: 0.8476\n",
      "Epoch 141/150\n",
      "329/329 [==============================] - 17s 53ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0231 - accuracy: 0.9049 - val_loss: 0.0682 - val_mse: 0.0682 - val_mae: 0.0560 - val_accuracy: 0.8546\n",
      "Epoch 142/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0211 - accuracy: 0.9086 - val_loss: 0.0789 - val_mse: 0.0789 - val_mae: 0.0805 - val_accuracy: 0.8111\n",
      "Epoch 143/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0269 - accuracy: 0.8906 - val_loss: 0.0699 - val_mse: 0.0699 - val_mae: 0.0608 - val_accuracy: 0.8544\n",
      "Epoch 144/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0198 - accuracy: 0.9135 - val_loss: 0.0695 - val_mse: 0.0695 - val_mae: 0.0551 - val_accuracy: 0.8609\n",
      "Epoch 145/150\n",
      "329/329 [==============================] - 17s 50ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0264 - accuracy: 0.8950 - val_loss: 0.0682 - val_mse: 0.0682 - val_mae: 0.0597 - val_accuracy: 0.8493\n",
      "Epoch 146/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0215 - accuracy: 0.9074 - val_loss: 0.0692 - val_mse: 0.0692 - val_mae: 0.0548 - val_accuracy: 0.8504\n",
      "Epoch 147/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0222 - accuracy: 0.9062 - val_loss: 0.0711 - val_mse: 0.0711 - val_mae: 0.0573 - val_accuracy: 0.8529\n",
      "Epoch 148/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0209 - accuracy: 0.9088 - val_loss: 0.0708 - val_mse: 0.0708 - val_mae: 0.0550 - val_accuracy: 0.8556\n",
      "Epoch 149/150\n",
      "329/329 [==============================] - 18s 54ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0258 - accuracy: 0.8991 - val_loss: 0.0706 - val_mse: 0.0706 - val_mae: 0.0590 - val_accuracy: 0.8530\n",
      "Epoch 150/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0210 - accuracy: 0.9090 - val_loss: 0.0690 - val_mse: 0.0690 - val_mae: 0.0551 - val_accuracy: 0.8546\n",
      "[INFO] evaluate the model...\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0690 - mse: 0.0690 - mae: 0.0551 - accuracy: 0.8546\n",
      "[INFO] making predictions on test data...\n",
      "219/219 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/150\n",
      "329/329 [==============================] - 18s 52ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0221 - accuracy: 0.9031 - val_loss: 0.0692 - val_mse: 0.0692 - val_mae: 0.0560 - val_accuracy: 0.8587\n",
      "Epoch 2/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0235 - accuracy: 0.9036 - val_loss: 0.0741 - val_mse: 0.0741 - val_mae: 0.0573 - val_accuracy: 0.8634\n",
      "Epoch 3/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0235 - accuracy: 0.8998 - val_loss: 0.0719 - val_mse: 0.0719 - val_mae: 0.0607 - val_accuracy: 0.8319\n",
      "Epoch 4/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0235 - accuracy: 0.9009 - val_loss: 0.0694 - val_mse: 0.0694 - val_mae: 0.0575 - val_accuracy: 0.8629\n",
      "Epoch 5/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0270 - accuracy: 0.8902 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.0560 - val_accuracy: 0.8627\n",
      "Epoch 6/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0210 - accuracy: 0.9115 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.0542 - val_accuracy: 0.8650\n",
      "Epoch 7/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0196 - accuracy: 0.9148 - val_loss: 0.0687 - val_mse: 0.0687 - val_mae: 0.0548 - val_accuracy: 0.8634\n",
      "Epoch 8/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 8.4247e-04 - mse: 8.4247e-04 - mae: 0.0181 - accuracy: 0.9189 - val_loss: 0.0678 - val_mse: 0.0678 - val_mae: 0.0610 - val_accuracy: 0.7956\n",
      "Epoch 9/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0230 - accuracy: 0.9007 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.0606 - val_accuracy: 0.8389\n",
      "Epoch 10/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0246 - accuracy: 0.8960 - val_loss: 0.0727 - val_mse: 0.0727 - val_mae: 0.0556 - val_accuracy: 0.8631\n",
      "Epoch 11/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0191 - accuracy: 0.9141 - val_loss: 0.0740 - val_mse: 0.0740 - val_mae: 0.0621 - val_accuracy: 0.8487\n",
      "Epoch 12/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0278 - accuracy: 0.8938 - val_loss: 0.0703 - val_mse: 0.0703 - val_mae: 0.0591 - val_accuracy: 0.8541\n",
      "Epoch 13/150\n",
      "329/329 [==============================] - 16s 50ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0207 - accuracy: 0.9104 - val_loss: 0.0839 - val_mse: 0.0839 - val_mae: 0.0693 - val_accuracy: 0.8186\n",
      "Epoch 14/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0238 - accuracy: 0.9000 - val_loss: 0.0682 - val_mse: 0.0682 - val_mae: 0.0551 - val_accuracy: 0.8669\n",
      "Epoch 15/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0232 - accuracy: 0.9017 - val_loss: 0.0809 - val_mse: 0.0809 - val_mae: 0.0709 - val_accuracy: 0.8149\n",
      "Epoch 16/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0258 - accuracy: 0.8926 - val_loss: 0.0744 - val_mse: 0.0744 - val_mae: 0.0629 - val_accuracy: 0.8370\n",
      "Epoch 17/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0242 - accuracy: 0.8994 - val_loss: 0.0672 - val_mse: 0.0672 - val_mae: 0.0547 - val_accuracy: 0.8540\n",
      "Epoch 18/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0203 - accuracy: 0.9117 - val_loss: 0.0820 - val_mse: 0.0820 - val_mae: 0.0860 - val_accuracy: 0.7750\n",
      "Epoch 19/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0253 - accuracy: 0.8999 - val_loss: 0.0675 - val_mse: 0.0675 - val_mae: 0.0593 - val_accuracy: 0.8549\n",
      "Epoch 20/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0214 - accuracy: 0.9089 - val_loss: 0.0681 - val_mse: 0.0681 - val_mae: 0.0547 - val_accuracy: 0.8553\n",
      "Epoch 21/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0199 - accuracy: 0.9112 - val_loss: 0.0683 - val_mse: 0.0683 - val_mae: 0.0544 - val_accuracy: 0.8643\n",
      "Epoch 22/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0211 - accuracy: 0.9083 - val_loss: 0.0704 - val_mse: 0.0704 - val_mae: 0.0558 - val_accuracy: 0.8540\n",
      "Epoch 23/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0202 - accuracy: 0.9111 - val_loss: 0.0697 - val_mse: 0.0697 - val_mae: 0.0636 - val_accuracy: 0.8250\n",
      "Epoch 24/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0292 - accuracy: 0.8887 - val_loss: 0.0755 - val_mse: 0.0755 - val_mae: 0.0632 - val_accuracy: 0.8386\n",
      "Epoch 25/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0222 - accuracy: 0.9069 - val_loss: 0.0706 - val_mse: 0.0706 - val_mae: 0.0568 - val_accuracy: 0.8564\n",
      "Epoch 26/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0224 - accuracy: 0.9071 - val_loss: 0.0697 - val_mse: 0.0697 - val_mae: 0.0550 - val_accuracy: 0.8581\n",
      "Epoch 27/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0205 - accuracy: 0.9100 - val_loss: 0.0679 - val_mse: 0.0679 - val_mae: 0.0547 - val_accuracy: 0.8547\n",
      "Epoch 28/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0188 - accuracy: 0.9178 - val_loss: 0.0709 - val_mse: 0.0709 - val_mae: 0.0578 - val_accuracy: 0.8609\n",
      "Epoch 29/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0245 - accuracy: 0.9000 - val_loss: 0.0745 - val_mse: 0.0745 - val_mae: 0.0677 - val_accuracy: 0.8253\n",
      "Epoch 30/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0304 - accuracy: 0.8822 - val_loss: 0.0713 - val_mse: 0.0713 - val_mae: 0.0568 - val_accuracy: 0.8567\n",
      "Epoch 31/150\n",
      "329/329 [==============================] - 16s 49ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0213 - accuracy: 0.9090 - val_loss: 0.0726 - val_mse: 0.0726 - val_mae: 0.0570 - val_accuracy: 0.8586\n",
      "Epoch 32/150\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0200 - accuracy: 0.9116 - val_loss: 0.0682 - val_mse: 0.0682 - val_mae: 0.0550 - val_accuracy: 0.8479\n",
      "Epoch 33/150\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 7.7019e-04 - mse: 7.7019e-04 - mae: 0.0175 - accuracy: 0.9179 - val_loss: 0.0679 - val_mse: 0.0679 - val_mae: 0.0545 - val_accuracy: 0.8593\n",
      "Epoch 34/150\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 8.0066e-04 - mse: 8.0066e-04 - mae: 0.0178 - accuracy: 0.9188 - val_loss: 0.0667 - val_mse: 0.0667 - val_mae: 0.0560 - val_accuracy: 0.8601\n",
      "Epoch 35/150\n",
      " 28/329 [=>............................] - ETA: 14s - loss: 8.2328e-04 - mse: 8.2328e-04 - mae: 0.0177 - accuracy: 0.9202"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# EntraÃ®nement du modÃ¨le\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] training model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m siamese_net\u001b[38;5;241m.\u001b[39mfit([data_left_train, data_right_train], affine_matrices_train,\n\u001b[0;32m     18\u001b[0m                           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[0;32m     19\u001b[0m                           validation_data\u001b[38;5;241m=\u001b[39m([data_left_test, data_right_test], affine_matrices_test))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Ã‰valuation du modÃ¨le sur les donnÃ©es de test\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] evaluate the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1789\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1787\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1788\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1789\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_hook(ModeKeys\u001b[38;5;241m.\u001b[39mTRAIN, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39mlogs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    327\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 393\u001b[0m     hook(batch, logs)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1093\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m-> 1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\generic_utils.py:296\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    293\u001b[0m         info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[1;32m--> 296\u001b[0m     io_utils\u001b[38;5;241m.\u001b[39mprint_msg(message, line_break\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    297\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\io_utils.py:81\u001b[0m, in \u001b[0;36mprint_msg\u001b[1;34m(message, line_break)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m         sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message)\n\u001b[1;32m---> 81\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(message)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py:488\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_timeout):\n\u001b[0;32m    489\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "mse_values = []  # List to store MSE values\n",
    "mae_values = []  # List to store MAE values\n",
    "accuracy_values = []  # List to store accuracy values\n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "for lr in learning_rates:\n",
    "    print(lr)\n",
    "    # DÃ©finition de l'optimizer Adam avec le learning rate correspondant\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    # Compilation du modÃ¨le avec l'optimizer et les mÃ©triques\n",
    "    siamese_net.compile(optimizer=optimizer, loss='mse', metrics=['mse', 'mae','accuracy'])\n",
    "\n",
    "    # EntraÃ®nement du modÃ¨le\n",
    "    print(\"[INFO] training model...\")\n",
    "    history = siamese_net.fit([data_left_train, data_right_train], affine_matrices_train,\n",
    "                              batch_size=64, epochs=150,\n",
    "                              validation_data=([data_left_test, data_right_test], affine_matrices_test))\n",
    "\n",
    "    # Ã‰valuation du modÃ¨le sur les donnÃ©es de test\n",
    "    print(\"[INFO] evaluate the model...\")\n",
    "    loss = siamese_net.evaluate([data_left_test, data_right_test], affine_matrices_test)\n",
    "    print(\"[INFO] making predictions on test data...\")\n",
    "    # Effectuer des prÃ©dictions sur les donnÃ©es de test\n",
    "    predictions = siamese_net.predict([data_left_test, data_right_test])\n",
    "\n",
    "    # Calculer MSE et MAE en comparant les prÃ©dictions avec les valeurs rÃ©elles\n",
    "    mse_value = np.mean((predictions - affine_matrices_test)**2)\n",
    "    mae_value = np.mean(np.abs(predictions - affine_matrices_test))\n",
    " \n",
    "    \n",
    "    # Store the values in the corresponding lists\n",
    "    mse_values.append(mse_value)\n",
    "    mae_values.append(mae_value)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d1886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TracÃ© de la courbe\n",
    "print('mse', mse_values)\n",
    "print('mae', mae_values)\n",
    "print('learning rates', learning_rates)\n",
    "plt.plot(range(len(learning_rates)), mse_values, label='MSE')\n",
    "plt.plot(range(len(learning_rates)), mae_values, label='MAE')\n",
    "#plt.plot(range(len(learning_rates)), accuracy_values, label='Accuracy')\n",
    "plt.title('Learning Rate Analysis(MCD Dataset)')\n",
    "plt.xticks(range(len(learning_rates)), learning_rates)\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('learningRateMCD.png')\n",
    "\n",
    "# Close the plot to avoid displaying it in the notebook\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = siamese_net.predict([data_left_test, data_right_test])\n",
    "mae = tf.keras.metrics.mean_absolute_error(affine_matrices_test, predictions).numpy()\n",
    "\n",
    "print(f\"Learning rate: {lr} - Test loss: {loss} - MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dee319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÃ©cupÃ©ration des historiques de MSE et MAE\n",
    "mse_history = history.history['mse']\n",
    "mae_history = history.history['mae']\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "  # Affichage des courbes de MSE et MAE\n",
    "plt.plot(mse_history, label='MSE')\n",
    "plt.plot(mae_history, label='MAE')\n",
    "#plt.plot(learning_rates, label='Learning Rate')\n",
    "\n",
    "# Configuration du graphique\n",
    "plt.title('MSE and MAE vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Affichage du graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870809fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "#MSE mesure Ã©galement la prÃ©cision des prÃ©visions en indiquant la moyenne des erreurs \n",
    "#au carrÃ© entre les valeurs prÃ©dites et les valeurs rÃ©elles.\n",
    "# Calculer la MSE entre les matrices prÃ©dites et rÃ©elles\n",
    "mse = mean_squared_error(affine_matrices_test, predictions)\n",
    "print(\"Mean Squared Error : \", mse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "#MAE mesure la prÃ©cision des prÃ©visions en indiquant la moyenne des erreurs absolues\n",
    "#entre les valeurs prÃ©dites et les valeurs rÃ©elles.\n",
    "# calculate mean absolute error\n",
    "mae = mean_absolute_error(affine_matrices_test, predictions)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd41b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_values = affine_matrices_test\n",
    "\n",
    "distances = []\n",
    "for i in range(len(predictions)):\n",
    "    dist = np.linalg.norm(real_values[i]- predictions[i])\n",
    "    distances.append(dist)\n",
    "\n",
    "mean_distance = np.mean(distances)\n",
    "print(\"Mean Euclidean Distance: \", mean_distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e473e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la matrice de transformation prÃ©dite\n",
    "print(predictions.shape)\n",
    "print(predictions[:,:])\n",
    "predictions_Re=predictions.reshape(predictions.shape[0],2,3)\n",
    "print(predictions_Re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(predictions[101,:])\n",
    "print(predictions[101,0])\n",
    "print(predictions[101,1])\n",
    "print(predictions[101,2])\n",
    "print(predictions[101,3])\n",
    "print(predictions[101,4])\n",
    "print(predictions[101,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5802b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(siamese_net.optimizer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TEST###\n",
    "c=3\n",
    "#DÃ©finir la matrice de transformation\n",
    "transformation_matrix =predictions[c,:]\n",
    "print(transformation_matrix)\n",
    "print(affine_matrices_test[c,:])\n",
    "#transformation_matrix = transformation_matrix.reshape(6, 1)\n",
    "# DÃ©finir le point Ã  transformer\n",
    " \n",
    "x11=data_left_test[c,0]\n",
    "x12=data_left_test[c,1]\n",
    "print(x11)\n",
    "x21=data_right_test[c,0]\n",
    "x22=data_right_test[c,1]\n",
    "Hx=x11*transformation_matrix[0]+x12*transformation_matrix[2]+transformation_matrix[4]\n",
    "Hy=x11*transformation_matrix[1]+x12*transformation_matrix[3]+transformation_matrix[5]\n",
    "print(Hx.shape)\n",
    "print(Hy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x11,x12,label=\" original  shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x21,x22,label=\"cible shape \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbc68a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Hx,Hy,label=\" transformed shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x11,x12,label=\" original  shape\",c='r')\n",
    "plt.plot(x21,x22,label=\"cible shape \",c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Hx,Hy,label=\" transformed shape\",c='r')\n",
    "plt.plot(x21,x22,label=\"cible shape \",c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7699fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot the curves for study\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2fa4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot the curves for study\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1028d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
